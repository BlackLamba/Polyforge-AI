{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97091baf-2c31-4d45-a434-080a729e5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import os\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73dd7969-d9c0-4a24-8eed-5ca3129afdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_smiles(smiles):\n",
    "    \"\"\"Проверка валидности SMILES строки\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol is not None\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f50ce2-71f3-457d-aa82-a6103deba377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем устройство: cuda\n",
      "True\n",
      "11.8\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 128\n",
    "EMB_DIM = 128\n",
    "LATENT_DIM = 64\n",
    "FF_DIM = 256\n",
    "N_HEADS = 8\n",
    "NUM_LAYERS = 2\n",
    "VOCAB_SPECIAL = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "DROPOUT = 0.1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используем устройство: {device}\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3ea8fa-e5ac-4b78-af2a-65dc7b0bdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и подготовка данных\n",
    "df = pd.read_csv(\"polymer_bigdata_merged.csv\")\n",
    "df = df.dropna(subset=[\"polymer_smiles\"])\n",
    "\n",
    "NUM_FEATURES = [\n",
    "    \"Enthalpy of Polymerization (kJ/mol)\",\n",
    "    \"Glass Transition Temperature (K)\",\n",
    "    \"Specific Heat Capacity (J {gK}^{-1})\",\n",
    "    \"Tensile Strength at break (MPa)\",\n",
    "    \"Thermal Decomposition Temperature (K)\",\n",
    "    \"Youngs Modulus (GPa)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58b55d8-ffaa-438c-a82b-61f4f35820a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[NUM_FEATURES] = scaler.fit_transform(df[NUM_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a578ede-df8b-493d-956e-8c46d617a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 52\n"
     ]
    }
   ],
   "source": [
    "def tokenize(smiles):\n",
    "    \"\"\"Токенизация SMILES строки\"\"\"\n",
    "    return list(smiles)\n",
    "\n",
    "all_tokens = set()\n",
    "for s in df[\"polymer_smiles\"]:\n",
    "    all_tokens.update(tokenize(s))\n",
    "\n",
    "tokens = VOCAB_SPECIAL + sorted(list(all_tokens))\n",
    "token2idx = {t: i for i, t in enumerate(tokens)}\n",
    "idx2token = {i: t for t, i in token2idx.items()}\n",
    "vocab_size = len(token2idx)\n",
    "print(f\"Размер словаря: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb2e6f5e-c293-498d-926d-396960321fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedConditionalSMILESDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_len=MAX_LEN):\n",
    "        self.data = dataframe[\"polymer_smiles\"].tolist()\n",
    "        self.features = dataframe[NUM_FEATURES].values.astype(np.float32)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def encode_smiles(self, smiles):\n",
    "        \"\"\"Кодирование SMILES в последовательность токенов\"\"\"\n",
    "        tokens = ['<bos>'] + tokenize(smiles) + ['<eos>']\n",
    "        if len(tokens) > self.max_len:\n",
    "            tokens = tokens[:self.max_len-1] + ['<eos>']\n",
    "        \n",
    "        token_ids = [token2idx.get(t, token2idx['<unk>']) for t in tokens]\n",
    "        padding = [token2idx['<pad>']] * (self.max_len - len(token_ids))\n",
    "        return torch.tensor(token_ids + padding)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.encode_smiles(self.data[idx])\n",
    "        tgt_input = x[:-1]\n",
    "        tgt_output = x[1:]\n",
    "        feats = torch.tensor(self.features[idx])\n",
    "        return tgt_input, tgt_output, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb67e12-5d5c-45aa-841e-5882a57c6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedConditionalTransformerVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, latent_dim, num_heads, ff_dim, num_layers, max_len, feature_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Embedding слои\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=token2idx['<pad>'])\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=ff_dim, \n",
    "            dropout=dropout,\n",
    "            batch_first=False,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Feature encoder\n",
    "        self.feat_encoder = nn.Sequential(\n",
    "            nn.Linear(feature_dim, latent_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(latent_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "        # Latent projection\n",
    "        self.fc_mu = nn.Linear(emb_dim + latent_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(emb_dim + latent_dim, latent_dim)\n",
    "\n",
    "        # Decoder projection\n",
    "        self.latent_to_emb = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=False,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "        # Инициализация весов\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "\n",
    "    def encode(self, src, feats):\n",
    "        \"\"\"Кодирование входной последовательности и признаков в латентное пространство\"\"\"\n",
    "        src_mask = (src == token2idx['<pad>']).bool()\n",
    "        src_emb = self.emb(src) + self.pos_emb[:, :src.size(1)]\n",
    "        src_emb = self.dropout(src_emb)\n",
    "        \n",
    "        # Transformer encoder ожидает [S, B, E]\n",
    "        src_emb = src_emb.transpose(0, 1)\n",
    "        src_enc = self.encoder(src_emb, src_key_padding_mask=src_mask)\n",
    "        \n",
    "        # Используем mean pooling вместо первого токена\n",
    "        cls_token = src_enc.mean(dim=0)  # [B, emb_dim]\n",
    "        \n",
    "        # Кодируем features\n",
    "        feats_emb = self.feat_encoder(feats)  # [B, latent_dim]\n",
    "        \n",
    "        # Объединяем для получения латентных переменных\n",
    "        combined = torch.cat([cls_token, feats_emb], dim=1)  # [B, emb_dim + latent_dim]\n",
    "        mu = self.fc_mu(combined)\n",
    "        logvar = self.fc_logvar(combined)\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        logvar = torch.clamp(logvar, min=-10, max=10)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, feats, tgt_inp):\n",
    "        tgt_key_padding_mask = (tgt_inp == token2idx['<pad>']).bool()\n",
    "    \n",
    "        feats_latent = self.feat_encoder(feats)\n",
    "        combined_latent = torch.cat([z, feats_latent], dim=1)\n",
    "        memory_vec = self.latent_to_emb(combined_latent)\n",
    "        \n",
    "        # ⭐⭐⭐ ИСПРАВЛЕНИЕ: memory должна быть [S, B, E] где S = длина последовательности\n",
    "        memory = memory_vec.unsqueeze(0)  # [1, B, E]\n",
    "        # НЕ повторяем по времени здесь - decoder сам обработает\n",
    "        \n",
    "        tgt_emb = self.emb(tgt_inp) + self.pos_emb[:, :tgt_inp.size(1)]\n",
    "        tgt_emb = self.dropout(tgt_emb)\n",
    "        tgt_emb = tgt_emb.transpose(0, 1)  # [T, B, E]\n",
    "        \n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_inp.size(1)).to(tgt_inp.device)\n",
    "        \n",
    "        out = self.decoder(\n",
    "            tgt=tgt_emb,\n",
    "            memory=memory,  # [1, B, E] - decoder сам расширит если нужно\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        \n",
    "        logits = self.out(out.transpose(0, 1))\n",
    "        return logits\n",
    "\n",
    "    def forward(self, src, feats, tgt_inp):\n",
    "        mu, logvar = self.encode(src, feats)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        logits = self.decode(z, feats, tgt_inp)\n",
    "        return logits, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f666ad9a-8a6a-4415-b68e-376cd3d5f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_vae_loss(logits, targets, mu, logvar, kl_weight=1.0, current_epoch=0, max_epochs=20):\n",
    "    \"\"\"Улучшенная функция потерь VAE с аннеалингом\"\"\"\n",
    "    recon_loss = F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)), \n",
    "        targets.view(-1), \n",
    "        ignore_index=token2idx['<pad>'],\n",
    "        label_smoothing=0.1\n",
    "    )\n",
    "    \n",
    "    kl_loss = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "    \n",
    "    # Увеличиваем kl_weight от 0 до 1 в течение эпох\n",
    "    if current_epoch < max_epochs:\n",
    "        annealing_factor = min(1.0, (current_epoch + 1) / (max_epochs * 0.5))  # плавный рост\n",
    "        kl_weight = kl_weight * annealing_factor\n",
    "    \n",
    "    total_loss = recon_loss + kl_weight * kl_loss\n",
    "    return total_loss, recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f838f3-4bc6-4dc4-8332-1a67947ff4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smiles_conditional_improved(model, target_feats, num_samples=5, temperature=0.7, max_length=MAX_LEN):\n",
    "    \"\"\"Улучшенная генерация SMILES с фильтрацией токенов\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        if not target_feats.is_cuda:\n",
    "            target_feats = target_feats.to(device)\n",
    "            \n",
    "        if target_feats.size(0) == 1:\n",
    "            target_feats = target_feats.repeat(num_samples, 1)\n",
    "        elif target_feats.size(0) < num_samples:\n",
    "            target_feats = target_feats[:num_samples]\n",
    "        elif target_feats.size(0) > num_samples:\n",
    "            target_feats = target_feats[:num_samples]\n",
    "        \n",
    "        actual_num_samples = target_feats.size(0)\n",
    "        \n",
    "        # Генерируем латентный вектор\n",
    "        z = torch.randn(actual_num_samples, model.latent_dim).to(device)\n",
    "        \n",
    "        # Кодируем features\n",
    "        feats_latent = model.feat_encoder(target_feats)\n",
    "        \n",
    "        # Объединяем для создания memory\n",
    "        combined_latent = torch.cat([z, feats_latent], dim=1)\n",
    "        memory_vec = model.latent_to_emb(combined_latent)\n",
    "        memory = memory_vec.unsqueeze(0)\n",
    "        \n",
    "        # Начальный токен\n",
    "        sequences = torch.tensor([token2idx['<bos>']] * actual_num_samples, device=device).unsqueeze(1)\n",
    "        finished = torch.zeros(actual_num_samples, dtype=torch.bool, device=device)\n",
    "        \n",
    "        for step in range(max_length - 1):\n",
    "            tgt_emb = model.emb(sequences) + model.pos_emb[:, :sequences.size(1)]\n",
    "            tgt_emb = tgt_emb.transpose(0, 1)\n",
    "            \n",
    "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(sequences.size(1)).to(device)\n",
    "            \n",
    "            out = model.decoder(tgt_emb, memory.repeat(sequences.size(1), 1, 1), tgt_mask=tgt_mask)\n",
    "            logits = model.out(out.transpose(0, 1))[:, -1] / temperature\n",
    "            \n",
    "            # ⭐⭐⭐ УЛУЧШЕННАЯ МАСКА: более строгая фильтрация ⭐⭐⭐\n",
    "            logits[:, token2idx['<pad>']] = -float('inf')\n",
    "            logits[:, token2idx['<bos>']] = -float('inf')\n",
    "            logits[:, token2idx['<unk>']] = -float('inf')\n",
    "            \n",
    "            # Маска для редких/проблемных символов\n",
    "            problem_tokens = ['p', '9', '@', '?', '!', '$', '%', '&', '*', '+', ';', ':', '\"', \"'\"]\n",
    "            for problem_token in problem_tokens:\n",
    "                if problem_token in token2idx:\n",
    "                    logits[:, token2idx[problem_token]] = -float('inf')\n",
    "            \n",
    "            # ⭐⭐⭐ TOP-K ФИЛЬТРАЦИЯ ⭐⭐⭐\n",
    "            top_k = min(30, logits.size(-1))\n",
    "            top_probs, top_indices = torch.topk(F.softmax(logits, dim=-1), top_k, dim=-1)\n",
    "            \n",
    "            # Сэмплируем из top-k\n",
    "            next_token = torch.zeros(actual_num_samples, dtype=torch.long, device=device)\n",
    "            for i in range(actual_num_samples):\n",
    "                if not finished[i]:\n",
    "                    sampled_idx = torch.multinomial(top_probs[i], 1)\n",
    "                    next_token[i] = top_indices[i, sampled_idx]\n",
    "            \n",
    "            sequences = torch.cat([sequences, next_token.unsqueeze(1)], dim=1)\n",
    "            \n",
    "            finished = finished | (next_token == token2idx['<eos>'])\n",
    "            if finished.all():\n",
    "                break\n",
    "        \n",
    "        return decode_sequences_improved(sequences.cpu())\n",
    "\n",
    "def decode_sequences_improved(sequences):\n",
    "    \"\"\"Улучшенное декодирование с балансировкой скобок\"\"\"\n",
    "    smiles_list = []\n",
    "    for seq in sequences:\n",
    "        tokens = []\n",
    "        open_brackets = 0\n",
    "        \n",
    "        for idx in seq[1:]:  # пропускаем <bos>\n",
    "            token = idx2token[idx.item()]\n",
    "            \n",
    "            if token == '<eos>':\n",
    "                break\n",
    "                \n",
    "            if token not in VOCAB_SPECIAL:\n",
    "                # Балансируем скобки\n",
    "                if token == '(':\n",
    "                    open_brackets += 1\n",
    "                elif token == ')':\n",
    "                    if open_brackets > 0:\n",
    "                        open_brackets -= 1\n",
    "                    else:\n",
    "                        continue  # пропускаем лишнюю закрывающую скобку\n",
    "                \n",
    "                tokens.append(token)\n",
    "        \n",
    "        # Добавляем недостающие закрывающие скобки\n",
    "        while open_brackets > 0:\n",
    "            tokens.append(')')\n",
    "            open_brackets -= 1\n",
    "        \n",
    "        smiles = ''.join(tokens)\n",
    "        \n",
    "        # Простая очистка очевидных ошибок\n",
    "        if '()' in smiles:\n",
    "            smiles = smiles.replace('()', '')\n",
    "        \n",
    "        smiles_list.append(smiles)\n",
    "    \n",
    "    return smiles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "028916a4-1314-44c0-b2c1-a2596109547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_display_improved(model, feats_tensor, num_samples=5, temperature=0.7):\n",
    "    \"\"\"Улучшенная генерация и визуализация\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if not feats_tensor.is_cuda:\n",
    "            feats_tensor = feats_tensor.to(device)\n",
    "            \n",
    "        smiles_list = generate_smiles_conditional_improved(model, feats_tensor, num_samples=num_samples, temperature=temperature)\n",
    "        \n",
    "        print(\"Сгенерированные SMILES (улучшенные):\")\n",
    "        valid_smiles = []\n",
    "        valid_mols = []\n",
    "        \n",
    "        for i, sm in enumerate(smiles_list):\n",
    "            # Базовая проверка перед валидацией\n",
    "            if len(sm) < 3 or sm.count('*') == len(sm):\n",
    "                validity = \"✗\"\n",
    "            else:\n",
    "                is_valid = is_valid_smiles(sm)\n",
    "                validity = \"✓\" if is_valid else \"✗\"\n",
    "                if is_valid:\n",
    "                    valid_smiles.append(sm)\n",
    "                    valid_mols.append(Chem.MolFromSmiles(sm))\n",
    "            \n",
    "            print(f\"{i+1}. {sm} {validity}\")\n",
    "        \n",
    "        # Визуализация\n",
    "        if valid_mols:\n",
    "            img = Draw.MolsToGridImage(valid_mols, molsPerRow=min(3, len(valid_mols)), \n",
    "                                     subImgSize=(300, 300), \n",
    "                                     legends=[f\"Valid {i+1}\" for i in range(len(valid_mols))])\n",
    "            display(img)\n",
    "            validity_rate = len(valid_mols) / num_samples * 100\n",
    "            print(f\"Валидных молекул: {len(valid_mols)}/{num_samples} ({validity_rate:.1f}%)\")\n",
    "        else:\n",
    "            print(\"Нет валидных молекул для отображения.\")\n",
    "            \n",
    "        return len(valid_mols) / num_samples if num_samples > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "650911f8-b4f2-424b-a2de-6aabe7f23dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, epoch):\n",
    "    \"\"\"Валидация модели\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_recon = 0\n",
    "    total_kl = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tgt_inp, tgt_out, feats in val_loader:\n",
    "            tgt_inp, tgt_out, feats = tgt_inp.to(device), tgt_out.to(device), feats.to(device)\n",
    "            logits, mu, logvar = model(tgt_inp, feats, tgt_inp)\n",
    "            loss, recon_loss, kl_loss = improved_vae_loss(logits, tgt_out, mu, logvar, current_epoch=epoch)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            total_kl += kl_loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_recon = total_recon / len(val_loader)\n",
    "    avg_kl = total_kl / len(val_loader)\n",
    "    \n",
    "    #  ИСПРАВЛЕНИЕ: согласование размеров \n",
    "    validity = 0\n",
    "    if epoch % 5 == 0:\n",
    "        valid_count = 0\n",
    "        total_count = 0\n",
    "        # Быстрая проверка - берем 5 примеров и генерируем по 2 SMILES для каждого\n",
    "        sample_feats = torch.tensor(val_df_limited[NUM_FEATURES].iloc[:5].values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Генерируем по 2 SMILES для каждого из 5 примеров\n",
    "        for i in range(5):\n",
    "            single_feat = sample_feats[i:i+1]  # [1, feature_dim]\n",
    "            generated = generate_smiles_conditional_improved(model, single_feat, num_samples=2)\n",
    "            for sm in generated:\n",
    "                total_count += 1\n",
    "                if is_valid_smiles(sm):\n",
    "                    valid_count += 1\n",
    "        \n",
    "        validity = valid_count / total_count if total_count > 0 else 0\n",
    "    \n",
    "    return avg_loss, avg_recon, avg_kl, validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e55e35f6-27b2-4943-be6d-5ecc5dae3384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочные данные: 9000 записей\n",
      "Валидационные данные: 1000 записей\n",
      "Размер тренировочного датасета: 9000\n",
      "Размер валидационного датасета: 1000\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "# valid_mask = df[\"polymer_smiles\"].apply(is_valid_smiles)\n",
    "# df = df[valid_mask].reset_index(drop=True)\n",
    "# print(f\"После валидации SMILES осталось {len(df)} записей\")\n",
    "\n",
    "# Подготовка данных\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Берем первые 9000 из тренировочных и 1000 из валидационных\n",
    "train_df_limited = train_df.head(9000).reset_index(drop=True)\n",
    "val_df_limited = val_df.head(1000).reset_index(drop=True)\n",
    "\n",
    "print(f\"Тренировочные данные: {len(train_df_limited)} записей\")\n",
    "print(f\"Валидационные данные: {len(val_df_limited)} записей\")\n",
    "\n",
    "train_dataset = ImprovedConditionalSMILESDataset(train_df_limited)\n",
    "val_dataset = ImprovedConditionalSMILESDataset(val_df_limited)\n",
    "\n",
    "# ⭐⭐⭐ ИСПРАВЛЕНИЕ: num_workers=0 для Jupyter ⭐⭐⭐\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "print(f\"Размер тренировочного датасета: {len(train_dataset)}\")\n",
    "print(f\"Размер валидационного датасета: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd79b89-eebe-47a9-964c-80c28fe82144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель создана: 729,908 параметров\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели\n",
    "model = ImprovedConditionalTransformerVAE(\n",
    "    vocab_size=vocab_size,\n",
    "    emb_dim=EMB_DIM,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_heads=N_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_len=MAX_LEN,\n",
    "    feature_dim=len(NUM_FEATURES),\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "print(f\"Модель создана: {sum(p.numel() for p in model.parameters()):,} параметров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fff8f05-39e4-40d8-8aee-212c53631922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизатор и scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=1e-4, \n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.98)\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0aee5f3-02ca-4c7f-a3b8-c3932d39a163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:03<00:00, 21.98it/s, Loss=2.7331, Recon=2.7130, KL=0.3021]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_smiles_conditional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     36\u001b[39m     train_bar.set_postfix({\n\u001b[32m     37\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mLoss\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m     38\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRecon\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecon_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \n\u001b[32m     39\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mKL\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkl_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     40\u001b[39m     })\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Валидация\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m avg_val_loss, avg_val_recon, avg_val_kl, validity = \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Сохранение метрик\u001b[39;00m\n\u001b[32m     46\u001b[39m avg_train_loss = total_train_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mvalidate_model\u001b[39m\u001b[34m(model, val_loader, epoch)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     32\u001b[39m     single_feat = sample_feats[i:i+\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# [1, feature_dim]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     generated = \u001b[43mgenerate_smiles_conditional\u001b[49m(model, single_feat, num_samples=\u001b[32m2\u001b[39m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sm \u001b[38;5;129;01min\u001b[39;00m generated:\n\u001b[32m     35\u001b[39m         total_count += \u001b[32m1\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_smiles_conditional' is not defined"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "EPOCHS = 30\n",
    "CHECKPOINT_DIR = 'checkpoints_conditional_vae'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_recon, val_recon = [], []\n",
    "train_kl, val_kl = [], []\n",
    "validities = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_recon = 0\n",
    "    total_train_kl = 0\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
    "    for tgt_inp, tgt_out, feats in train_bar:\n",
    "        tgt_inp, tgt_out, feats = tgt_inp.to(device), tgt_out.to(device), feats.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, mu, logvar = model(tgt_inp, feats, tgt_inp)\n",
    "        loss, recon_loss, kl_loss = improved_vae_loss(logits, tgt_out, mu, logvar, current_epoch=epoch, max_epochs=EPOCHS)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        total_train_recon += recon_loss.item()\n",
    "        total_train_kl += kl_loss.item()\n",
    "        \n",
    "        train_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Recon': f'{recon_loss.item():.4f}', \n",
    "            'KL': f'{kl_loss.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    # Валидация\n",
    "    avg_val_loss, avg_val_recon, avg_val_kl, validity = validate_model(model, val_loader, epoch)\n",
    "    \n",
    "    # Сохранение метрик\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_recon = total_train_recon / len(train_loader)\n",
    "    avg_train_kl = total_train_kl / len(train_loader)\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    train_recon.append(avg_train_recon)\n",
    "    val_recon.append(avg_val_recon)\n",
    "    train_kl.append(avg_train_kl)\n",
    "    val_kl.append(avg_val_kl)\n",
    "    validities.append(validity)\n",
    "    \n",
    "    # Обновление scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}:\")\n",
    "    print(f\"  Train - Loss: {avg_train_loss:.4f}, Recon: {avg_train_recon:.4f}, KL: {avg_train_kl:.4f}\")\n",
    "    print(f\"  Val   - Loss: {avg_val_loss:.4f}, Recon: {avg_val_recon:.4f}, KL: {avg_val_kl:.4f}\")\n",
    "    print(f\"  Validity: {validity:.2%}\")\n",
    "    print(f\"  LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    # Сохранение лучшей модели\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'token2idx': token2idx,\n",
    "            'scaler': scaler\n",
    "        }, os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "        print(\"  ✓ Сохранена лучшая модель\")\n",
    "    \n",
    "    # # Генерация примеров каждые 5 эпох\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "    #     print(\"  Генерация примеров:\")\n",
    "    #     # ⭐⭐⭐ Берем один пример и генерируем несколько SMILES ⭐⭐⭐\n",
    "    #     sample_feats = torch.tensor(val_df[NUM_FEATURES].iloc[:1].values, dtype=torch.float32).to(device)\n",
    "    #     generate_and_display_smiles(model, sample_feats, num_samples=3, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97456805-6b67-4ee6-bd22-e42e7eb03412",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Общий Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_recon, label='Train Recon')\n",
    "plt.plot(val_recon, label='Val Recon')\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(validities, label='Validity', color='green')\n",
    "plt.title('Валидность сгенерированных SMILES')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validity')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5842e-cb96-4acc-ab97-acf5ae5d5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальное сохранение\n",
    "torch.save(model.state_dict(), \"improved_transformer_smiles_conditional.pth\")\n",
    "print(\"Модель сохранена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742dfab-5f3e-4540-aceb-238f6d743b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование финальной модели\n",
    "print(\"Финальная генерация:\")\n",
    "sample_feats = torch.tensor(val_df[NUM_FEATURES].iloc[:3].values, dtype=torch.float32).to(device)  # ← ДОБАВЬТЕ .to(device)\n",
    "generate_and_display_improved(model, sample_feats, num_samples=6, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744aaa12-72bf-49b5-9e08-fc4e718a035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Тестирование с разными температурами\n",
    "print(\"=== Генерация с разными температурами ===\")\n",
    "\n",
    "sample_feats = torch.tensor(val_df[NUM_FEATURES].iloc[:1].values, dtype=torch.float32).to(device)\n",
    "\n",
    "for temp in [0.5, 0.7, 0.9, 1.1]:\n",
    "    print(f\"\\n--- Температура: {temp} ---\")\n",
    "    smiles_list, valid_smiles = generate_and_display_improved(model, sample_feats, num_samples=5, temperature=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575e209-79ea-4e5b-9d22-1e3dcaa2e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== ТЕСТИРОВАНИЕ УЛУЧШЕННОЙ ГЕНЕРАЦИИ ===\")\n",
    "\n",
    "# Тестируем на разных примерах\n",
    "sample_indices = [0, 10, 50]  # разные молекулы из валидационного набора\n",
    "for idx in sample_indices:\n",
    "    print(f\"\\n--- Пример {idx} ---\")\n",
    "    sample_feats = torch.tensor(val_df[NUM_FEATURES].iloc[idx:idx+1].values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Оригинальная молекула\n",
    "    original_smiles = val_df.iloc[idx][\"polymer_smiles\"]\n",
    "    print(f\"Оригинальная SMILES: {original_smiles}\")\n",
    "    print(f\"Валидность оригинала: {'✓' if is_valid_smiles(original_smiles) else '✗'}\")\n",
    "    \n",
    "    # Генерация с улучшенным методом\n",
    "    validity_rate = generate_and_display_improved(model, sample_feats, num_samples=6, temperature=0.7)\n",
    "    print(f\"Процент валидности: {validity_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50885ec4-de12-4ad0-817c-97bda04ed80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка лучшей модели для инференса\n",
    "def load_best_model():\n",
    "    checkpoint = torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Загружена лучшая модель с эпохи {checkpoint['epoch']}, val_loss: {checkpoint['val_loss']:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f5af8-8150-4760-a995-4a4d383eda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка если нужно\n",
    "# model = load_best_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
