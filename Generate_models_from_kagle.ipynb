{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T06:38:19.846872Z",
     "start_time": "2025-07-07T06:38:17.248849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import openpyxl\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdmolops"
   ],
   "id": "9075107c0422faa3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T06:39:32.303805Z",
     "start_time": "2025-07-07T06:39:29.336074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CFG:\n",
    "    TARGETS = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "    SEED = 42\n",
    "    FOLDS = 5\n",
    "    PATH = 'E:/Code/Poliforge/Polyforge-AI/data/models_from_kagle_train/'\n",
    "\n",
    "train = pd.read_csv(CFG.PATH + 'train.csv')\n",
    "test = pd.read_csv(CFG.PATH + 'test.csv')\n",
    "\n",
    "def make_smile_canonical(smile): # To avoid duplicates, for example: canonical '*C=C(*)C' == '*C(=C*)C'\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        canon_smile = Chem.MolToSmiles(mol, canonical=True)\n",
    "        return canon_smile\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "train['SMILES'] = train['SMILES'].apply(lambda s: make_smile_canonical(s))\n",
    "test['SMILES'] = test['SMILES'].apply(lambda s: make_smile_canonical(s))"
   ],
   "id": "aae7c5c6ec19cf71",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T08:02:03.144684Z",
     "start_time": "2025-07-07T08:02:01.810869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/datasets/minatoyukinaxlisa/tc-smiles\n",
    "data_tc = pd.read_csv(CFG.PATH + 'Tc_SMILES.csv')\n",
    "data_tc = data_tc.rename(columns={'TC_mean': 'Tc'})\n",
    "\n",
    "# https://springernature.figshare.com/articles/dataset/dataset_with_glass_transition_temperature/24219958?file=42507037\n",
    "data_tg2 = pd.read_csv(CFG.PATH + 'JCIM_sup_bigsmiles.csv', usecols=['SMILES', 'Tg (C)'])\n",
    "data_tg2 = data_tg2.rename(columns={'Tg (C)': 'Tg'})\n",
    "\n",
    "# https://www.sciencedirect.com/science/article/pii/S2590159123000377#ec0005\n",
    "data_tg3 = pd.read_excel(CFG.PATH + 'data_tg3.xlsx')\n",
    "data_tg3 = data_tg3.rename(columns={'Tg [K]': 'Tg'})\n",
    "data_tg3['Tg'] = data_tg3['Tg'] - 273.15\n",
    "\n",
    "# https://github.com/Duke-MatSci/ChemProps\n",
    "data_dnst = pd.read_excel(CFG.PATH + 'raw_data.xlsx')\n",
    "data_dnst = data_dnst.rename(columns={'density(g/cm3)': 'Density'})[['SMILES', 'Density']]\n",
    "data_dnst['SMILES'] = data_dnst['SMILES'].apply(lambda s: make_smile_canonical(s))\n",
    "data_dnst = data_dnst[(data_dnst['SMILES'].notnull())&(data_dnst['Density'].notnull())&(data_dnst['Density'] != 'nylon')]\n",
    "data_dnst['Density'] = data_dnst['Density'].astype('float64')\n",
    "data_dnst['Density'] -= 0.118\n",
    "\n",
    "def add_extra_data(df_train, df_extra, target):\n",
    "    n_samples_before = len(df_train[df_train[target].notnull()])\n",
    "    \n",
    "    df_extra['SMILES'] = df_extra['SMILES'].apply(lambda s: make_smile_canonical(s))\n",
    "    df_extra = df_extra.groupby('SMILES', as_index=False)[target].mean()\n",
    "    cross_smiles = set(df_extra['SMILES']) & set(df_train['SMILES'])\n",
    "    unique_smiles_extra = set(df_extra['SMILES']) - set(df_train['SMILES'])\n",
    "\n",
    "    # Make priority target value from competition's df\n",
    "    for smile in df_train[df_train[target].notnull()]['SMILES'].tolist():\n",
    "        if smile in cross_smiles:\n",
    "            cross_smiles.remove(smile)\n",
    "\n",
    "    # Imput missing values for competition's SMILES\n",
    "    for smile in cross_smiles:\n",
    "        df_train.loc[df_train['SMILES']==smile, target] = df_extra[df_extra['SMILES']==smile][target].values[0]\n",
    "    \n",
    "    df_train = pd.concat([df_train, df_extra[df_extra['SMILES'].isin(unique_smiles_extra)]], axis=0).reset_index(drop=True)\n",
    "\n",
    "    n_samples_after = len(df_train[df_train[target].notnull()])\n",
    "    print(f'\\nFor target \"{target}\" added {n_samples_after-n_samples_before} new samples!')\n",
    "    print(f'New unique SMILES: {len(unique_smiles_extra)}')\n",
    "    return df_train\n",
    "\n",
    "train = add_extra_data(train, data_tc, 'Tc')\n",
    "train = add_extra_data(train, data_tg2, 'Tg')\n",
    "train = add_extra_data(train, data_tg3, 'Tg')\n",
    "train = add_extra_data(train, data_dnst, 'Density')\n",
    "\n",
    "print('\\n'*3, '--- SMILES for training ---', )\n",
    "for t in CFG.TARGETS:\n",
    "    print(f'\"{t}\": {len(train[train[t].notnull()])}')"
   ],
   "id": "429e75fc48165400",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:02:02] SMILES Parse Error: syntax error while parsing: *O[Si](*)([R])[R]\n",
      "[11:02:02] SMILES Parse Error: check for mistakes around position 12:\n",
      "[11:02:02] *O[Si](*)([R])[R]\n",
      "[11:02:02] ~~~~~~~~~~~^\n",
      "[11:02:02] SMILES Parse Error: Failed parsing SMILES '*O[Si](*)([R])[R]' for input: '*O[Si](*)([R])[R]'\n",
      "[11:02:02] SMILES Parse Error: syntax error while parsing: *NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4\n",
      "[11:02:02] SMILES Parse Error: check for mistakes around position 28:\n",
      "[11:02:02] c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=\n",
      "[11:02:02] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[11:02:02] SMILES Parse Error: Failed parsing SMILES '*NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4' for input: '*NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4'\n",
      "[11:02:02] SMILES Parse Error: syntax error while parsing: O=C=N[R1]N=C=O.O[R2]O.O[R3]O\n",
      "[11:02:02] SMILES Parse Error: check for mistakes around position 7:\n",
      "[11:02:02] O=C=N[R1]N=C=O.O[R2]O.O[R3]O\n",
      "[11:02:02] ~~~~~~^\n",
      "[11:02:02] SMILES Parse Error: Failed parsing SMILES 'O=C=N[R1]N=C=O.O[R2]O.O[R3]O' for input: 'O=C=N[R1]N=C=O.O[R2]O.O[R3]O'\n",
      "[11:02:02] SMILES Parse Error: syntax error while parsing: *CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O\n",
      "[11:02:02] SMILES Parse Error: check for mistakes around position 6:\n",
      "[11:02:02] *CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*\n",
      "[11:02:02] ~~~~~^\n",
      "[11:02:02] SMILES Parse Error: Failed parsing SMILES '*CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O' for input: '*CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O'\n",
      "[11:02:02] SMILES Parse Error: syntax error while parsing: *C(F)(F)CC(F)([R])C(*)(F)F\n",
      "[11:02:02] SMILES Parse Error: check for mistakes around position 16:\n",
      "[11:02:02] *C(F)(F)CC(F)([R])C(*)(F)F\n",
      "[11:02:02] ~~~~~~~~~~~~~~~^\n",
      "[11:02:02] SMILES Parse Error: Failed parsing SMILES '*C(F)(F)CC(F)([R])C(*)(F)F' for input: '*C(F)(F)CC(F)([R])C(*)(F)F'\n",
      "[11:02:02] SMILES Parse Error: syntax error while parsing: *OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]\n",
      "[11:02:02] SMILES Parse Error: check for mistakes around position 11:\n",
      "[11:02:02] *OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O\n",
      "[11:02:02] ~~~~~~~~~~^\n",
      "[11:02:02] SMILES Parse Error: Failed parsing SMILES '*OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]' for input: '*OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For target \"Tc\" added 129 new samples!\n",
      "New unique SMILES: 129\n",
      "\n",
      "For target \"Tg\" added 151 new samples!\n",
      "New unique SMILES: 136\n",
      "\n",
      "For target \"Tg\" added 499 new samples!\n",
      "New unique SMILES: 499\n",
      "\n",
      "For target \"Density\" added 634 new samples!\n",
      "New unique SMILES: 524\n",
      "\n",
      "\n",
      "\n",
      " --- SMILES for training ---\n",
      "\"Tg\": 1161\n",
      "\"FFV\": 7030\n",
      "\"Tc\": 866\n",
      "\"Density\": 1247\n",
      "\"Rg\": 614\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T08:34:00.183733Z",
     "start_time": "2025-07-07T08:32:27.637027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "useless_cols = [    \n",
    "    # Nan data\n",
    "    'BCUT2D_MWHI',\n",
    "    'BCUT2D_MWLOW',\n",
    "    'BCUT2D_CHGHI',\n",
    "    'BCUT2D_CHGLO',\n",
    "    'BCUT2D_LOGPHI',\n",
    "    'BCUT2D_LOGPLOW',\n",
    "    'BCUT2D_MRHI',\n",
    "    'BCUT2D_MRLOW',\n",
    "\n",
    "    # Constant data\n",
    "    'NumRadicalElectrons',\n",
    "    'SMR_VSA8',\n",
    "    'SlogP_VSA9',\n",
    "    'fr_barbitur',\n",
    "    'fr_benzodiazepine',\n",
    "    'fr_dihydropyridine',\n",
    "    'fr_epoxide',\n",
    "    'fr_isothiocyan',\n",
    "    'fr_lactam',\n",
    "    'fr_nitroso',\n",
    "    'fr_prisulfonamd',\n",
    "    'fr_thiocyan',\n",
    "\n",
    "    # High correlated data >0.95\n",
    "    'MaxEStateIndex',\n",
    "    'HeavyAtomMolWt',\n",
    "    'ExactMolWt',\n",
    "    'NumValenceElectrons',\n",
    "    'Chi0',\n",
    "    'Chi0n',\n",
    "    'Chi0v',\n",
    "    'Chi1',\n",
    "    'Chi1n',\n",
    "    'Chi1v',\n",
    "    'Chi2n',\n",
    "    'Kappa1',\n",
    "    'LabuteASA',\n",
    "    'HeavyAtomCount',\n",
    "    'MolMR',\n",
    "    'Chi3n',\n",
    "    'BertzCT',\n",
    "    'Chi2v',\n",
    "    'Chi4n',\n",
    "    'HallKierAlpha',\n",
    "    'Chi3v',\n",
    "    'Chi4v',\n",
    "    'MinAbsPartialCharge',\n",
    "    'MinPartialCharge',\n",
    "    'MaxAbsPartialCharge',\n",
    "    'FpDensityMorgan2',\n",
    "    'FpDensityMorgan3',\n",
    "    'Phi',\n",
    "    'Kappa3',\n",
    "    'fr_nitrile',\n",
    "    'SlogP_VSA6',\n",
    "    'NumAromaticCarbocycles',\n",
    "    'NumAromaticRings',\n",
    "    'fr_benzene',\n",
    "    'VSA_EState6',\n",
    "    'NOCount',\n",
    "    'fr_C_O',\n",
    "    'fr_C_O_noCOO',\n",
    "    'NumHDonors',\n",
    "    'fr_amide',\n",
    "    'fr_Nhpyrrole',\n",
    "    'fr_phenol',\n",
    "    'fr_phenol_noOrthoHbond',\n",
    "    'fr_COO2',\n",
    "    'fr_halogen',\n",
    "    'fr_diazo',\n",
    "    'fr_nitro_arom',\n",
    "    'fr_phos_ester'\n",
    "]\n",
    "\n",
    "def compute_all_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [None] * len(desc_names)\n",
    "    return [desc[1](mol) for desc in Descriptors.descList if desc[0] not in useless_cols]\n",
    "\n",
    "def compute_graph_features(smiles, graph_feats):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    adj = rdmolops.GetAdjacencyMatrix(mol)\n",
    "    G = nx.from_numpy_array(adj)\n",
    "\n",
    "    graph_feats['graph_diameter'].append(nx.diameter(G) if nx.is_connected(G) else 0)\n",
    "    graph_feats['avg_shortest_path'].append(nx.average_shortest_path_length(G) if nx.is_connected(G) else 0)\n",
    "    graph_feats['num_cycles'].append(len(list(nx.cycle_basis(G))))\n",
    "\n",
    "def preprocessing(df):\n",
    "    desc_names = [desc[0] for desc in Descriptors.descList if desc[0] not in useless_cols]\n",
    "    descriptors = [compute_all_descriptors(smi) for smi in df['SMILES'].to_list()]\n",
    "\n",
    "    graph_feats = {'graph_diameter': [], 'avg_shortest_path': [], 'num_cycles': []}\n",
    "    for smile in df['SMILES']:\n",
    "         compute_graph_features(smile, graph_feats)\n",
    "        \n",
    "    result = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(descriptors, columns=desc_names),\n",
    "            pd.DataFrame(graph_feats)\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    result = result.replace([-np.inf, np.inf], np.nan)\n",
    "    return result\n",
    "\n",
    "# Сначала определим имена новых столбцов\n",
    "desc_names = [desc[0] for desc in Descriptors.descList if desc[0] not in useless_cols]\n",
    "graph_feats_cols = ['graph_diameter', 'avg_shortest_path', 'num_cycles']\n",
    "all_new_cols = desc_names + graph_feats_cols\n",
    "\n",
    "# Обработаем train\n",
    "preprocessed_train = preprocessing(train)\n",
    "# Удалим дубликаты столбцов из исходного DataFrame\n",
    "train = train.drop(columns=[col for col in all_new_cols if col in train.columns], errors='ignore')\n",
    "train = pd.concat([train, preprocessed_train], axis=1)\n",
    "\n",
    "# То же самое для test\n",
    "preprocessed_test = preprocessing(test)\n",
    "test = test.drop(columns=[col for col in all_new_cols if col in test.columns], errors='ignore')\n",
    "test = pd.concat([test, preprocessed_test], axis=1)\n",
    "\n",
    "# Find constant columns for each target\n",
    "all_features = train.columns[7:].tolist()\n",
    "features = {}\n",
    "for target in CFG.TARGETS:\n",
    "    const_descs = []\n",
    "    for col in train.columns.drop(CFG.TARGETS):\n",
    "        if train[train[target].notnull()][col].nunique() == 1:\n",
    "            const_descs.append(col)\n",
    "    features[target] = [f for f in all_features if f not in const_descs]"
   ],
   "id": "a21aa043558922c2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T10:34:32.590417Z",
     "start_time": "2025-07-07T10:24:35.418012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return sum(abs(true - pred) for true, pred in zip(y_true, y_pred)) / len(y_true)\n",
    "\n",
    "base_params = {\n",
    "    'device_type': 'cpu',\n",
    "    'n_estimators': 1_000_000,\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    \n",
    "    'num_leaves': 50,\n",
    "    'min_data_in_leaf': 2,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_bin': 500,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 2,\n",
    "    'lambda_l2': 2,\n",
    "}\n",
    "\n",
    "for target in CFG.TARGETS:\n",
    "    print(f'\\n\\nTARGET {target}')\n",
    "    train_part = train[train[target].notnull()].reset_index(drop=True)\n",
    "    train[f'{target}_pred'] = 0\n",
    "    test[target] = 0\n",
    "    oof_lgb = np.zeros(len(train_part))\n",
    "    scores = []\n",
    "    \n",
    "    kf = KFold(n_splits=CFG.FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "    for i, (trn_idx, val_idx) in enumerate(kf.split(train_part, train_part[target])):\n",
    "        print(f\"\\n--- Fold {i+1} ---\")\n",
    "        \n",
    "        x_trn = train_part.loc[trn_idx, features[target]]\n",
    "        y_trn = train_part.loc[trn_idx, target]\n",
    "        x_val = train_part.loc[val_idx, features[target]]\n",
    "        y_val = train_part.loc[val_idx, target]\n",
    "\n",
    "        model_lgb = lgb.LGBMRegressor(**base_params)\n",
    "        model_lgb.fit(\n",
    "            x_trn, y_trn,\n",
    "            eval_set=[(x_val, y_val)],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(\n",
    "                    stopping_rounds=300,\n",
    "                    verbose=False,\n",
    "                ),\n",
    "                lgb.log_evaluation(2500)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        with open(f'E:/Code/Poliforge/Polyforge-AI/models/lgb_{target}_fold_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(model_lgb, f)\n",
    "\n",
    "        val_preds = model_lgb.predict(x_val, num_iteration=model_lgb.best_iteration_)\n",
    "        score = mae(y_val, val_preds)\n",
    "        scores.append(score)\n",
    "        print(f'MAE: {np.round(score, 5)}')\n",
    "        \n",
    "        oof_lgb[val_idx] = val_preds\n",
    "        test[target] += model_lgb.predict(\n",
    "            test[features[target]], \n",
    "            num_iteration=model_lgb.best_iteration_\n",
    "        ) / CFG.FOLDS\n",
    "\n",
    "    train.loc[train[target].notnull(), f'{target}_pred'] = oof_lgb\n",
    "\n",
    "    print(f'\\nMean MAE: {np.round(np.mean(scores), 5)}')\n",
    "    print(f'Std MAE: {np.round(np.std(scores), 5)}')\n",
    "    print('-'*30)"
   ],
   "id": "df18667daadb813d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TARGET Tg\n",
      "\n",
      "--- Fold 1 ---\n",
      "MAE: 36.99332\n",
      "\n",
      "--- Fold 2 ---\n",
      "MAE: 34.48545\n",
      "\n",
      "--- Fold 3 ---\n",
      "MAE: 34.65471\n",
      "\n",
      "--- Fold 4 ---\n",
      "MAE: 37.3359\n",
      "\n",
      "--- Fold 5 ---\n",
      "MAE: 37.82849\n",
      "\n",
      "Mean MAE: 36.25957\n",
      "Std MAE: 1.40581\n",
      "------------------------------\n",
      "\n",
      "\n",
      "TARGET FFV\n",
      "\n",
      "--- Fold 1 ---\n",
      "[2500]\tvalid_0's l1: 0.00712088\n",
      "[5000]\tvalid_0's l1: 0.00680728\n",
      "[7500]\tvalid_0's l1: 0.00667209\n",
      "[10000]\tvalid_0's l1: 0.00662393\n",
      "[12500]\tvalid_0's l1: 0.00659899\n",
      "[15000]\tvalid_0's l1: 0.00658114\n",
      "[17500]\tvalid_0's l1: 0.00656699\n",
      "[20000]\tvalid_0's l1: 0.00655216\n",
      "[22500]\tvalid_0's l1: 0.00653873\n",
      "[25000]\tvalid_0's l1: 0.00653014\n",
      "MAE: 0.00652\n",
      "\n",
      "--- Fold 2 ---\n",
      "[2500]\tvalid_0's l1: 0.00672036\n",
      "[5000]\tvalid_0's l1: 0.00640957\n",
      "[7500]\tvalid_0's l1: 0.0062889\n",
      "[10000]\tvalid_0's l1: 0.00623596\n",
      "MAE: 0.00622\n",
      "\n",
      "--- Fold 3 ---\n",
      "[2500]\tvalid_0's l1: 0.00659018\n",
      "[5000]\tvalid_0's l1: 0.00629288\n",
      "[7500]\tvalid_0's l1: 0.00616722\n",
      "[10000]\tvalid_0's l1: 0.00611136\n",
      "[12500]\tvalid_0's l1: 0.00607492\n",
      "[15000]\tvalid_0's l1: 0.00605841\n",
      "[17500]\tvalid_0's l1: 0.00604172\n",
      "[20000]\tvalid_0's l1: 0.00602666\n",
      "[22500]\tvalid_0's l1: 0.00601559\n",
      "[25000]\tvalid_0's l1: 0.00600689\n",
      "MAE: 0.006\n",
      "\n",
      "--- Fold 4 ---\n",
      "[2500]\tvalid_0's l1: 0.00634789\n",
      "[5000]\tvalid_0's l1: 0.00602779\n",
      "[7500]\tvalid_0's l1: 0.00593146\n",
      "[10000]\tvalid_0's l1: 0.00588494\n",
      "[12500]\tvalid_0's l1: 0.00586103\n",
      "[15000]\tvalid_0's l1: 0.00584792\n",
      "[17500]\tvalid_0's l1: 0.00583104\n",
      "MAE: 0.00582\n",
      "\n",
      "--- Fold 5 ---\n",
      "[2500]\tvalid_0's l1: 0.00674229\n",
      "[5000]\tvalid_0's l1: 0.00645789\n",
      "[7500]\tvalid_0's l1: 0.00631623\n",
      "[10000]\tvalid_0's l1: 0.00627111\n",
      "[12500]\tvalid_0's l1: 0.00624975\n",
      "MAE: 0.00624\n",
      "\n",
      "Mean MAE: 0.00616\n",
      "Std MAE: 0.00024\n",
      "------------------------------\n",
      "\n",
      "\n",
      "TARGET Tc\n",
      "\n",
      "--- Fold 1 ---\n",
      "MAE: 0.02838\n",
      "\n",
      "--- Fold 2 ---\n",
      "MAE: 0.02776\n",
      "\n",
      "--- Fold 3 ---\n",
      "[2500]\tvalid_0's l1: 0.0409791\n",
      "MAE: 0.04063\n",
      "\n",
      "--- Fold 4 ---\n",
      "MAE: 0.02732\n",
      "\n",
      "--- Fold 5 ---\n",
      "MAE: 0.03058\n",
      "\n",
      "Mean MAE: 0.03094\n",
      "Std MAE: 0.00498\n",
      "------------------------------\n",
      "\n",
      "\n",
      "TARGET Density\n",
      "\n",
      "--- Fold 1 ---\n",
      "[2500]\tvalid_0's l1: 0.0397066\n",
      "[5000]\tvalid_0's l1: 0.0389764\n",
      "[7500]\tvalid_0's l1: 0.0386005\n",
      "[10000]\tvalid_0's l1: 0.0384005\n",
      "MAE: 0.03835\n",
      "\n",
      "--- Fold 2 ---\n",
      "[2500]\tvalid_0's l1: 0.0413701\n",
      "MAE: 0.04134\n",
      "\n",
      "--- Fold 3 ---\n",
      "MAE: 0.03871\n",
      "\n",
      "--- Fold 4 ---\n",
      "[2500]\tvalid_0's l1: 0.039785\n",
      "[5000]\tvalid_0's l1: 0.0393314\n",
      "MAE: 0.03925\n",
      "\n",
      "--- Fold 5 ---\n",
      "MAE: 0.03488\n",
      "\n",
      "Mean MAE: 0.0385\n",
      "Std MAE: 0.00209\n",
      "------------------------------\n",
      "\n",
      "\n",
      "TARGET Rg\n",
      "\n",
      "--- Fold 1 ---\n",
      "MAE: 1.86181\n",
      "\n",
      "--- Fold 2 ---\n",
      "MAE: 1.81282\n",
      "\n",
      "--- Fold 3 ---\n",
      "MAE: 1.87923\n",
      "\n",
      "--- Fold 4 ---\n",
      "MAE: 1.54327\n",
      "\n",
      "--- Fold 5 ---\n",
      "MAE: 1.65489\n",
      "\n",
      "Mean MAE: 1.7504\n",
      "Std MAE: 0.13033\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T10:34:56.272736Z",
     "start_time": "2025-07-07T10:34:56.258610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MINMAX_DICT =  {\n",
    "        'Tg': [-148.0297376, 472.25],\n",
    "        'FFV': [0.2269924, 0.77709707],\n",
    "        'Tc': [0.0465, 0.524],\n",
    "        'Density': [0.748691234, 1.840998909],\n",
    "        'Rg': [9.7283551, 34.672905605],\n",
    "    }\n",
    "NULL_FOR_SUBMISSION = -9999\n",
    "\n",
    "def scaling_error(labels, preds, property):\n",
    "    error = np.abs(labels - preds)\n",
    "    min_val, max_val = MINMAX_DICT[property]\n",
    "    label_range = max_val - min_val\n",
    "    return np.mean(error / label_range)\n",
    "\n",
    "def get_property_weights(labels):\n",
    "    property_weight = []\n",
    "    for property in MINMAX_DICT.keys():\n",
    "        valid_num = np.sum(labels[property] != NULL_FOR_SUBMISSION)\n",
    "        property_weight.append(valid_num)\n",
    "    property_weight = np.array(property_weight)\n",
    "    property_weight = np.sqrt(1 / property_weight)\n",
    "    return (property_weight / np.sum(property_weight)) * len(property_weight)\n",
    "\n",
    "def wmae_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    chemical_properties = list(MINMAX_DICT.keys())\n",
    "    property_maes = []\n",
    "    property_weights = get_property_weights(solution[chemical_properties])\n",
    "    for property in chemical_properties:\n",
    "        is_labeled = solution[property] != NULL_FOR_SUBMISSION\n",
    "        property_maes.append(scaling_error(solution.loc[is_labeled, property], submission.loc[is_labeled, property], property))\n",
    "\n",
    "    if len(property_maes) == 0:\n",
    "        raise RuntimeError('No labels')\n",
    "    return float(np.average(property_maes, weights=property_weights))\n",
    "\n",
    "tr_solution = train[['id'] + CFG.TARGETS]\n",
    "tr_submission = train[['id'] + [t + '_pred' for t in CFG.TARGETS]]\n",
    "tr_submission.columns = ['id'] + CFG.TARGETS\n",
    "print(f\"wMAE: {round(wmae_score(tr_solution, tr_submission, row_id_column_name='id'), 5)}\")"
   ],
   "id": "1cdf6641598b8776",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wMAE: 0.04797\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
