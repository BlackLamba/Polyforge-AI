{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01631ad4-1d04-4539-b8a0-7e804a30f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import os\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0433b05-fa75-406d-b8e7-54c19ed52677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol is not None\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67481334-460d-4f1f-b287-f52ab800980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "EMB_DIM = 256\n",
    "LATENT_DIM = 128\n",
    "N_HEADS = 8\n",
    "FF_DIM = 512\n",
    "NUM_LAYERS = 4\n",
    "VOCAB_SPECIAL = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используем устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532493a8-52b2-4212-ac4d-7bd5f20fa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"polymer_bigdata_merged.csv\")\n",
    "df = df.dropna(subset=[\"polymer_smiles\"])\n",
    "\n",
    "# Фильтруем по длине SMILES, чтобы убрать мусор/очень длинные строки\n",
    "df = df[df[\"polymer_smiles\"].str.len() > 2]\n",
    "df = df[df[\"polymer_smiles\"].str.len() < MAX_LEN-2]  # учтём <bos>/<eos>\n",
    "\n",
    "# Берём только первые 25 000 записей для обучения (или меньше, если данных меньше)\n",
    "subset_df = df.iloc[:10000].copy()\n",
    "\n",
    "NUM_FEATURES = [\n",
    "    \"Enthalpy of Polymerization (kJ/mol)\",\n",
    "    \"Glass Transition Temperature (K)\",\n",
    "    \"Specific Heat Capacity (J {gK}^{-1})\",\n",
    "    \"Tensile Strength at break (MPa)\",\n",
    "    \"Thermal Decomposition Temperature (K)\",\n",
    "    \"Youngs Modulus (GPa)\"\n",
    "]\n",
    "\n",
    "# Убедимся, что фичи не постоянные (иначе MinMax даст NaN)\n",
    "for f in NUM_FEATURES:\n",
    "    if subset_df[f].max() == subset_df[f].min():\n",
    "        print(f\"Warning: feature {f} is constant. Filling with zeros.\")\n",
    "        subset_df[f] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1417634-94b3-4c3e-89c7-3b07392335a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "subset_df[NUM_FEATURES] = scaler.fit_transform(subset_df[NUM_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42def4a7-a4f6-4c1e-b75e-e5c056d1807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(smiles):\n",
    "    return list(smiles)\n",
    "\n",
    "all_tokens = set()\n",
    "for s in subset_df[\"polymer_smiles\"]:\n",
    "    all_tokens.update(tokenize(s))\n",
    "\n",
    "tokens = VOCAB_SPECIAL + sorted(list(all_tokens))\n",
    "token2idx = {t: i for i, t in enumerate(tokens)}\n",
    "idx2token = {i: t for t, i in token2idx.items()}\n",
    "vocab_size = len(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d0a5e5-e96c-4904-8f62-9d6d91ef50cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalSMILESDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe[\"polymer_smiles\"].tolist()\n",
    "        self.features = dataframe[NUM_FEATURES].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def encode_smiles(self, smiles):\n",
    "        tokens_seq = ['<bos>'] + list(smiles) + ['<eos>']\n",
    "        token_ids = [token2idx.get(t, token2idx['<unk>']) for t in tokens_seq]\n",
    "        token_ids = token_ids[:MAX_LEN]\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            token_ids += [token2idx['<pad>']] * (MAX_LEN - len(token_ids))\n",
    "        return torch.tensor(token_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.encode_smiles(self.data[idx])\n",
    "        tgt_input = x[:-1]\n",
    "        tgt_output = x[1:]\n",
    "        feats = torch.tensor(self.features[idx])\n",
    "        return tgt_input, tgt_output, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82ca159-a0e8-4684-a01c-8dc122c3c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalTransformerVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, latent_dim, num_heads, ff_dim, num_layers, max_len, feature_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=token2idx['<pad>'])\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.feat_encoder = nn.Linear(feature_dim, latent_dim)\n",
    "        self.fc_mu = nn.Linear(emb_dim + latent_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(emb_dim + latent_dim, latent_dim)\n",
    "        self.decoder_proj = nn.Linear(latent_dim + latent_dim, emb_dim)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=emb_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.out = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "        # Инициализация весов (Xavier) для стабилизации\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def encode(self, src, feats):\n",
    "        src_mask = (src == token2idx['<pad>']).bool()\n",
    "        src_emb = self.emb(src) + self.pos_emb[:, :src.size(1)]\n",
    "        src_enc = self.encoder(src_emb.transpose(0,1), src_key_padding_mask=src_mask)\n",
    "        cls_token = src_enc[0, :, :]\n",
    "        feats_emb = self.feat_encoder(feats)\n",
    "        combined = torch.cat([cls_token, feats_emb], dim=1)\n",
    "        mu = self.fc_mu(combined)\n",
    "        logvar = self.fc_logvar(combined)\n",
    "        # не клэмпим здесь окончательно — клэмпим при вычислении KL\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Защита: клэмпим logvar до разумного максимума перед exp\n",
    "        logvar = torch.clamp(logvar, min=-10, max=4)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, feats, tgt_inp):\n",
    "        tgt_mask = (tgt_inp == token2idx['<pad>']).bool()\n",
    "        z_dec = torch.cat([z, self.feat_encoder(feats)], dim=1).unsqueeze(1).repeat(1, tgt_inp.size(1), 1)\n",
    "        tgt_emb = self.emb(tgt_inp) + self.pos_emb[:, :tgt_inp.size(1)]\n",
    "        tgt_seq_mask = nn.Transformer.generate_square_subsequent_mask(tgt_inp.size(1)).to(z.device)\n",
    "        out = self.decoder(tgt=tgt_emb.transpose(0,1), memory=z_dec.transpose(0,1), tgt_mask=tgt_seq_mask, tgt_key_padding_mask=tgt_mask)\n",
    "        logits = self.out(out.transpose(0,1))\n",
    "        return logits\n",
    "\n",
    "    def forward(self, src, feats, tgt_inp):\n",
    "        mu, logvar = self.encode(src, feats)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        logits = self.decode(z, feats, tgt_inp)\n",
    "        return logits, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d099be23-9624-4a6e-b68a-c5ee1c74c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_vae_loss(logits, targets, mu, logvar, beta=0.1, pad_idx=token2idx['<pad>']):\n",
    "    # Reconstruction\n",
    "    recon_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=pad_idx)\n",
    "    # KL: используем клэмпнутый logvar для стабильности\n",
    "    clamped_logvar = torch.clamp(logvar, min=-10, max=4)\n",
    "    kl_per_sample = -0.5 * torch.sum(1 + clamped_logvar - mu.pow(2) - clamped_logvar.exp(), dim=1)\n",
    "    kl_loss = torch.mean(kl_per_sample)\n",
    "    total_loss = recon_loss + beta * kl_loss\n",
    "    return total_loss, recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfe1bca-c64d-42e9-ab7f-ec481d150ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smiles_conditional(model, target_feats, num_samples=5, temperature=1.0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, LATENT_DIM).to(device)\n",
    "        target_feats = target_feats.to(device)\n",
    "        z_dec = torch.cat([z, model.feat_encoder(target_feats)], dim=1).unsqueeze(1)\n",
    "        input_token = torch.tensor([token2idx['<bos>']] * num_samples).unsqueeze(1).to(device)\n",
    "        sequences = input_token\n",
    "        finished = torch.zeros(num_samples, dtype=torch.bool).to(device)\n",
    "\n",
    "        for _ in range(MAX_LEN - 1):\n",
    "            emb = model.emb(sequences) + model.pos_emb[:, :sequences.size(1)]\n",
    "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(sequences.size(1)).to(device)\n",
    "            out = model.decoder(emb.transpose(0,1), z_dec.transpose(0,1), tgt_mask=tgt_mask)\n",
    "            logits = model.out(out.transpose(0,1))[:, -1] / temperature\n",
    "            # Защита: если logits содержат NaN — заменим их на очень низкие числа\n",
    "            if torch.isnan(logits).any():\n",
    "                logits = torch.nan_to_num(logits, nan=-1e9, posinf=1e9, neginf=-1e9)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "            finished = finished | (next_token == token2idx['<eos>'])\n",
    "            if finished.all(): break\n",
    "            sequences = torch.cat([sequences, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "        smiles_list = []\n",
    "        for seq in sequences:\n",
    "            tokens_seq = [idx2token[i.item()] for i in seq]\n",
    "            if '<eos>' in tokens_seq:\n",
    "                tokens_seq = tokens_seq[:tokens_seq.index('<eos>')]\n",
    "            smiles = ''.join([t for t in tokens_seq if t not in VOCAB_SPECIAL])\n",
    "            smiles_list.append(smiles)\n",
    "        return smiles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86b8d25-7c19-4645-a123-4c2d9a88577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goxps\\Desktop\\polyForge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = ConditionalSMILESDataset(subset_df)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "model = ConditionalTransformerVAE(\n",
    "    vocab_size=len(token2idx),\n",
    "    emb_dim=EMB_DIM,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_heads=N_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_len=MAX_LEN,\n",
    "    feature_dim=len(NUM_FEATURES)\n",
    ").to(device)\n",
    "\n",
    "# чуть меньший lr для дополнительной стабильности\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69932f5-b080-4ae2-8f57-6954f470db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                                                                                                                                                             | 0/313 [00:00<?, ?it/s]C:\\Users\\goxps\\Desktop\\polyForge\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 221/313 [00:32<00:08, 11.24it/s]"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = 'checkpoints_VAE'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint_conditional.pth')\n",
    "\n",
    "start_epoch = 0\n",
    "best_loss = float('inf')\n",
    "loss_history = []\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_recon = 0.0\n",
    "    total_kl = 0.0\n",
    "\n",
    "    # beta-annealing для KL (плавное нарастание)\n",
    "    beta = min(1.0, (epoch + 1) / 10.0)\n",
    "\n",
    "    for tgt_inp, tgt_out, feats in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        tgt_inp, tgt_out, feats = tgt_inp.to(device), tgt_out.to(device), feats.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, mu, logvar = model(tgt_inp, feats, tgt_inp)\n",
    "\n",
    "        # защита: если в логитах NaN — заменим или пропустим шаг\n",
    "        if torch.isnan(logits).any():\n",
    "            print(\"NaN in logits detected! Skipping batch.\")\n",
    "            continue\n",
    "\n",
    "        loss, recon_loss, kl_loss = conditional_vae_loss(logits, tgt_out, mu, logvar, beta=beta)\n",
    "\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(\"NaN/Inf detected in loss! Skipping step\")\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_recon += recon_loss.item()\n",
    "        total_kl += kl_loss.item()\n",
    "\n",
    "    # безопасная агрегация (если все батчи были пропущены, не делим на 0)\n",
    "    n_batches = len(loader)\n",
    "    avg_loss = total_loss / n_batches if n_batches > 0 else float('nan')\n",
    "    avg_recon = total_recon / n_batches if n_batches > 0 else float('nan')\n",
    "    avg_kl = total_kl / n_batches if n_batches > 0 else float('nan')\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f} | beta: {beta:.3f}\")\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint сохранён на {checkpoint_path} (лучший по Loss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b322c67-b00d-4f0b-857d-b1ca96272659",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.title(\"Обучение Conditional VAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a125501-0425-4d53-890d-738c06cb99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"transformer_smiles_conditional.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f0e81-c8cb-4727-8b44-9a31e549cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация 100 молекул по средним признакам обучающего поднабора\n",
    "model.eval()\n",
    "mean_feats = torch.tensor(subset_df[NUM_FEATURES].mean().values, dtype=torch.float32).unsqueeze(0)\n",
    "num_generate = 100\n",
    "target_feats = mean_feats.repeat(num_generate, 1)\n",
    "\n",
    "generated_smiles = generate_smiles_conditional(model, target_feats, num_samples=num_generate, temperature=0.8)\n",
    "valid_smiles = [s for s in generated_smiles if is_valid_smiles(s)]\n",
    "print(f\"Сгенерировано {len(valid_smiles)} валидных SMILES из {num_generate}\")\n",
    "\n",
    "# Отобразим первые 10 молекул\n",
    "mols = [Chem.MolFromSmiles(s) for s in valid_smiles[:10]]\n",
    "if len(mols) > 0:\n",
    "    img = Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200,200))\n",
    "    display(img)\n",
    "\n",
    "# Выводим все сгенерированные валидные SMILES\n",
    "print(\"Все сгенерированные валидные SMILES:\")\n",
    "for i, s in enumerate(valid_smiles, 1):\n",
    "    print(f\"{i}: {s}\")\n",
    "\n",
    "# пример задания признаков: максимизируем терм. разложение\n",
    "example_feats = subset_df[NUM_FEATURES].mean().values\n",
    "example_feats[NUM_FEATURES.index(\"Thermal Decomposition Temperature (K)\")] = 1.0\n",
    "example_feats = torch.tensor(example_feats, dtype=torch.float32).unsqueeze(0)\n",
    "target_feats = example_feats.repeat(num_generate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec331bc3-f143-4687-b089-86dbe78c675c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
